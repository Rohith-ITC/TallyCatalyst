// Unified Cache Sync Manager
// Consolidates sync logic, progress tracking, and cache utilities
import { hybridCache } from './hybridCache';
import { apiPost, apiGet } from './apiUtils';
import { deobfuscateStockItems } from './frontendDeobfuscate';
import { getApiUrl } from '../config';

// Cache version and utilities
export const CACHE_VERSION = process.env.REACT_APP_VERSION || '1.0.0';
export const CACHE_KEY_PREFIX = 'datalynk_';

// Helper: Add cache buster to URLs
export const addCacheBuster = (url) => {
  const separator = url.includes('?') ? '&' : '?';
  return `${url}${separator}_t=${Date.now()}`;
};

// Clear all application caches (preserves auth data)
export const clearAllCaches = () => {
  try {
    console.log('üßπ clearAllCaches called');
    
    // Clear localStorage
    const keys = Object.keys(localStorage);
    keys.forEach(key => {
      if (key.startsWith(CACHE_KEY_PREFIX)) {
        localStorage.removeItem(key);
      }
    });
    
    // Clear only cache-related sessionStorage items, NOT authentication tokens
    const authKeys = ['token', 'email', 'name', 'tallyloc_id', 'company', 'guid', 'status', 'access_type'];
    const sessionKeys = Object.keys(sessionStorage);
    
    let clearedCount = 0;
    sessionKeys.forEach(key => {
      const isCacheKey = key.startsWith(CACHE_KEY_PREFIX) || 
                        key.startsWith('ledgerlist-w-addrs_') || 
                        key.startsWith('stockitem_');
      const isAuthKey = authKeys.includes(key);
      
      if (!isAuthKey && isCacheKey) {
        sessionStorage.removeItem(key);
        clearedCount++;
      }
    });
    
    // Clear service worker caches if available
    if ('caches' in window) {
      caches.keys().then(cacheNames => {
        cacheNames.forEach(cacheName => {
          caches.delete(cacheName);
        });
      });
    }
    
    console.log(`üßπ All caches cleared successfully (authentication data preserved). Cleared ${clearedCount} cache keys`);
  } catch (error) {
    console.error('Error clearing caches:', error);
  }
};

// Check if app version has changed
export const checkVersionUpdate = () => {
  const storedVersion = localStorage.getItem(`${CACHE_KEY_PREFIX}version`);
  
  // Don't clear if storedVersion is a placeholder (build issue)
  if (storedVersion && storedVersion.includes('%') && storedVersion.includes('REACT_APP_VERSION')) {
    console.log('‚ö†Ô∏è Detected placeholder version, setting to current version without clearing');
    localStorage.setItem(`${CACHE_KEY_PREFIX}version`, CACHE_VERSION);
    return false;
  }
  
  if (storedVersion && storedVersion !== CACHE_VERSION) {
    console.log(`üîÑ Version changed from ${storedVersion} to ${CACHE_VERSION} - clearing caches`);
    clearAllCaches();
    localStorage.setItem(`${CACHE_KEY_PREFIX}version`, CACHE_VERSION);
    return true;
  } else if (!storedVersion) {
    console.log('üîÑ No stored version found, setting initial version');
    localStorage.setItem(`${CACHE_KEY_PREFIX}version`, CACHE_VERSION);
  }
  
  return false;
};

// Force reload with cache busting
export const forceReload = () => {
  const timestamp = new Date().getTime();
  const currentUrl = new URL(window.location.href);
  currentUrl.searchParams.set('_t', timestamp);
  clearAllCaches();
  window.location.href = currentUrl.toString();
};

// Detect mobile device
const isMobileDevice = () => {
  return /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
};

// Fetch with timeout and retry logic
// Increased timeout and retries for large data downloads
const fetchWithTimeout = async (url, options, timeout = 300000, retries = 10) => {
  const isMobile = isMobileDevice();
  // Use longer timeout for large data - 5 minutes default, 7.5 minutes for mobile
  const effectiveTimeout = isMobile ? 450000 : timeout;
  
  for (let attempt = 1; attempt <= retries; attempt++) {
    try {
      const controller = new AbortController();
      const timeoutId = setTimeout(() => {
        controller.abort();
      }, effectiveTimeout);
      
      try {
        const response = await fetch(url, {
          ...options,
          signal: controller.signal,
          cache: 'no-cache',
          mode: 'cors',
          credentials: 'omit'
        });
        
        clearTimeout(timeoutId);
        
        if (!response.ok) {
          const errorText = await response.text().catch(() => 'Unable to read error message');
          throw new Error(`HTTP ${response.status}: ${response.statusText}. ${errorText.substring(0, 200)}`);
        }
        
        return response;
      } catch (fetchError) {
        clearTimeout(timeoutId);
        throw fetchError;
      }
    } catch (error) {
      const isTimeout = error.name === 'AbortError' || error.message.includes('timeout');
      const isNetworkError = error.message.includes('Failed to fetch') || error.message.includes('NetworkError') || error.message.includes('Network request failed');
      
      // Don't retry on non-retryable errors
      if (!isTimeout && !isNetworkError && !error.message.includes('504') && !error.message.includes('408') && !error.message.includes('502')) {
        throw error;
      }
      
      // If last attempt, throw detailed error
      if (attempt === retries) {
        throw new Error(
          `Failed after ${retries} attempts. ` +
          `Last error: ${error.message}. ` +
          `Device: ${isMobile ? 'Mobile' : 'Desktop'}. ` +
          `Online: ${navigator.onLine}. ` +
          `Please check your internet connection and try again.`
        );
      }
      
      // Wait before retrying (exponential backoff)
      const delay = Math.min(1000 * Math.pow(2, attempt - 1), 5000);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
};

// Helper functions for date conversion
const convertDateToYYYYMMDD = (dateString) => {
  if (!dateString) return null;
  if (/^\d{8}$/.test(dateString)) return dateString;
  if (/^\d{4}-\d{2}-\d{2}$/.test(dateString)) return dateString.replace(/-/g, '');

  const monthNames = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec'];
  try {
    const parts = dateString.split('-');
    if (parts.length === 3) {
      const day = parseInt(parts[0], 10);
      const monthName = parts[1].toLowerCase();
      const year = parseInt(parts[2], 10);
      const monthIndex = monthNames.findIndex(m => m === monthName);
      if (monthIndex === -1) return null;
      const fullYear = year < 50 ? 2000 + year : (year < 100 ? 1900 + year : year);
      const month = String(monthIndex + 1).padStart(2, '0');
      const dayStr = String(day).padStart(2, '0');
      return `${fullYear}${month}${dayStr}`;
    }
  } catch (error) {
    console.warn('Error parsing date:', dateString, error);
  }
  return null;
};

const formatDateForAPI = (dateString) => {
  const converted = convertDateToYYYYMMDD(dateString);
  if (converted) return converted;
  if (dateString.includes('-')) return dateString.replace(/-/g, '');
  return dateString;
};

const splitDateRange = (startDate, endDate) => {
  const chunks = [];
  const start = new Date(startDate);
  const end = new Date(endDate);
  let currentStart = new Date(start);
  while (currentStart <= end) {
    let currentEnd = new Date(currentStart);
    currentEnd.setDate(currentEnd.getDate() + 1); // 2-day chunks (start + 1 day = 2 days total)
    if (currentEnd > end) currentEnd = new Date(end);
    chunks.push({
      start: currentStart.toISOString().split('T')[0],
      end: currentEnd.toISOString().split('T')[0]
    });
    currentStart.setDate(currentStart.getDate() + 2); // Move to next chunk (2 days forward)
  }
  return chunks;
};

const calculateMaxAlterId = (data) => {
  if (!data || !data.vouchers || !Array.isArray(data.vouchers)) return null;
  let maxAlterId = null;
  for (const voucher of data.vouchers) {
    const alterid = voucher.alterid || voucher.ALTERID;
    if (alterid !== null && alterid !== undefined) {
      const numId = typeof alterid === 'string' ? parseInt(alterid, 10) : alterid;
      if (!isNaN(numId) && (maxAlterId === null || numId > maxAlterId)) {
        maxAlterId = numId;
      }
    }
  }
  return maxAlterId;
};

const fetchBooksFrom = async (selectedGuid) => {
  try {
    // Check sessionStorage first
    const booksfromDirect = sessionStorage.getItem('booksfrom');
    if (booksfromDirect) {
      return booksfromDirect;
    }

    // Check allConnections in sessionStorage
    const connectionsStr = sessionStorage.getItem('allConnections');
    const connections = JSON.parse(connectionsStr || '[]');
    
    if (selectedGuid && Array.isArray(connections)) {
      const company = connections.find(c => c.guid === selectedGuid);
      if (company && company.booksfrom) {
        return company.booksfrom;
      }
    }

    // Fallback to API call
    const response = await apiGet(`/api/tally/user-connections?ts=${Date.now()}`);
    
    if (response) {
      let apiConnections = [];
      if (Array.isArray(response)) {
        apiConnections = response;
      } else if (response.createdByMe && response.sharedWithMe) {
        const created = Array.isArray(response.createdByMe) ? response.createdByMe : [];
        const shared = Array.isArray(response.sharedWithMe) ? response.sharedWithMe : [];
        apiConnections = [...created, ...shared];
      }
      
      const company = apiConnections.find(c => c.guid === selectedGuid);
      if (company && company.booksfrom) {
        sessionStorage.setItem('booksfrom', company.booksfrom);
        return company.booksfrom;
      }
    }
    
    return null;
  } catch (error) {
    console.error('Error in fetchBooksFrom:', error);
    return null;
  }
};

// Get sync progress key for storing in cache
const getSyncProgressKey = (email, guid) => {
  return `sync_progress_${email}_${guid}`;
};

// Get email from sessionStorage
const getUserEmail = () => {
  return sessionStorage.getItem('email');
};

// Internal sync function that does the actual work
const syncSalesDataInternal = async (companyInfo, email, onProgress = () => {}) => {
  if (!companyInfo) {
    throw new Error('No company selected');
  }

  console.log('üöÄ Starting syncSalesData for company:', {
    tallyloc_id: companyInfo.tallyloc_id,
    company: companyInfo.company,
    guid: companyInfo.guid,
    email
  });

  const progressKey = getSyncProgressKey(email, companyInfo.guid);
  let savedProgress = null;

  try {
    // Load saved progress if exists
    try {
      savedProgress = await hybridCache.getDashboardState(progressKey);
    } catch (e) {
      console.warn('Could not load saved progress:', e);
    }

    // Update progress to in_progress
    await hybridCache.setDashboardState(progressKey, {
      email,
      companyGuid: companyInfo.guid,
      tallylocId: companyInfo.tallyloc_id,
      status: 'in_progress',
      lastUpdated: Date.now(),
      chunksCompleted: savedProgress?.chunksCompleted || 0,
      totalChunks: savedProgress?.totalChunks || 0
    });

    const booksfrom = await fetchBooksFrom(companyInfo.guid);
    
    if (!booksfrom) {
      throw new Error('Unable to fetch booksfrom date. Please ensure you have access to this company.');
    }

    const lastaltid = savedProgress?.lastSyncedAlterId || await hybridCache.getLastAlterId(companyInfo, email);
    const isUpdate = !!lastaltid;

    const today = new Date();
    const todayStr = `${today.getFullYear()}-${String(today.getMonth() + 1).padStart(2, '0')}-${String(today.getDate()).padStart(2, '0')}`;
    const todayAPI = formatDateForAPI(todayStr);

    let booksFromFormatted = todayAPI;
    if (booksfrom) {
      booksFromFormatted = convertDateToYYYYMMDD(booksfrom) || formatDateForAPI(booksfrom);
    }

    const payload = {
      tallyloc_id: companyInfo.tallyloc_id,
      company: companyInfo.company,
      guid: companyInfo.guid,
      fromdate: booksFromFormatted,
      todate: todayAPI,
      serverslice: isUpdate ? "Yes" : "No"
    };

    if (isUpdate && lastaltid) {
      payload.lastaltid = lastaltid;
    }

    onProgress({ current: 0, total: 1, message: isUpdate ? 'Checking for updates...' : 'Fetching data...' });

    const salesextractUrl = `${getApiUrl('/api/reports/salesextract')}?ts=${Date.now()}`;
    const token = sessionStorage.getItem('token');
    const headers = {
      'Content-Type': 'application/json',
      ...(token ? { Authorization: `Bearer ${token}` } : {})
    };

    let response;
    let needsSlice = false;
    const shouldUseChunking = !isUpdate;

    if (!shouldUseChunking) {
      try {
        const fetchResponse = await fetchWithTimeout(
          salesextractUrl,
          {
            method: 'POST',
            headers,
            body: JSON.stringify(payload),
          },
          300000, // 5 minutes timeout
          5 // Increased retries
        );

        const responseText = await fetchResponse.text();
        if (!responseText) throw new Error('Empty response from server');
        response = JSON.parse(responseText);
        
        if (response && response.frontendslice === 'Yes') {
          needsSlice = true;
        } else {
          needsSlice = response && (
            response.message === 'slice' ||
            response.message === 'Slice' ||
            response.message?.toLowerCase().includes('slice') ||
            (response.error && response.error.toLowerCase().includes('slice'))
          );
        }
      } catch (error) {
        if (error.message.includes('timeout') || error.message.includes('504') || error.message.includes('408') || error.message.includes('Failed after')) {
          needsSlice = true;
        } else {
          throw error;
        }
      }
    } else {
      needsSlice = true;
    }

    let allVouchers = [];
    let mergedData = { vouchers: [] };
    let chunks = null;

    // For updates, load existing data FIRST before processing chunks to ensure we preserve it
    let existingVouchersForMerge = [];
    if (isUpdate) {
      try {
        const existingData = await hybridCache.getCompleteSalesData(companyInfo, email);
        if (existingData && existingData.data && existingData.data.vouchers && existingData.data.vouchers.length > 0) {
          existingVouchersForMerge = existingData.data.vouchers;
          console.log(`üìä Pre-loaded ${existingVouchersForMerge.length} existing vouchers for update merge`);
        }
      } catch (error) {
        console.warn('‚ö†Ô∏è Could not pre-load existing cache for update:', error);
      }
    }

    if (needsSlice || shouldUseChunking) {
      let startDateForChunks = todayStr;
      if (booksfrom) {
        const booksfromYYYYMMDD = convertDateToYYYYMMDD(booksfrom);
        if (booksfromYYYYMMDD && booksfromYYYYMMDD.length === 8) {
          startDateForChunks = `${booksfromYYYYMMDD.slice(0, 4)}-${booksfromYYYYMMDD.slice(4, 6)}-${booksfromYYYYMMDD.slice(6, 8)}`;
        }
      }
      chunks = splitDateRange(startDateForChunks, todayStr);

      // Resume from saved chunk if available
      const startChunkIndex = savedProgress?.chunksCompleted || 0;

      onProgress({ 
        current: startChunkIndex, 
        total: chunks.length, 
        message: `Syncing ${companyInfo.company}: Resuming from chunk ${startChunkIndex + 1} of ${chunks.length}...`,
        companyGuid: companyInfo.guid,
        companyName: companyInfo.company
      });

      // Update total chunks in progress
      await hybridCache.setDashboardState(progressKey, {
        email,
        companyGuid: companyInfo.guid,
        tallylocId: companyInfo.tallyloc_id,
        status: 'in_progress',
        lastUpdated: Date.now(),
        chunksCompleted: startChunkIndex,
        totalChunks: chunks.length
      });

      for (let i = startChunkIndex; i < chunks.length; i++) {
        const chunk = chunks[i];
        onProgress({
          current: i + 1,
          total: chunks.length,
          message: `Syncing ${companyInfo.company}: ${i + 1} / ${chunks.length} chunks`,
          companyGuid: companyInfo.guid,
          companyName: companyInfo.company
        });

        const chunkPayload = {
          ...payload,
          fromdate: formatDateForAPI(chunk.start),
          todate: formatDateForAPI(chunk.end),
          serverslice: "No"
        };

        try {
          const chunkFetchResponse = await fetchWithTimeout(
            salesextractUrl,
            {
              method: 'POST',
              headers,
              body: JSON.stringify(chunkPayload),
            },
            300000, // 5 minutes timeout for large chunks
            10 // Increased retries to 10 for better resilience
          );

          const chunkResponseText = await chunkFetchResponse.text();
          if (chunkResponseText) {
            const chunkResponse = JSON.parse(chunkResponseText);
            if (chunkResponse && chunkResponse.vouchers && Array.isArray(chunkResponse.vouchers)) {
              allVouchers.push(...chunkResponse.vouchers);
            }
          }

          // Update progress after each chunk
          const chunkProgress = {
            email,
            companyGuid: companyInfo.guid,
            tallylocId: companyInfo.tallyloc_id,
            status: 'in_progress',
            lastUpdated: Date.now(),
            chunksCompleted: i + 1,
            totalChunks: chunks.length
          };
          await hybridCache.setDashboardState(progressKey, chunkProgress);
          console.log(`üìä Progress updated: ${i + 1}/${chunks.length} chunks for ${companyInfo.company}`);
          
          // Notify subscribers if this is the currently active sync
          if (onProgress) {
            onProgress({
              current: i + 1,
              total: chunks.length,
              message: `Syncing ${companyInfo.company}: ${i + 1} / ${chunks.length} chunks`,
              companyGuid: companyInfo.guid,
              companyName: companyInfo.company
            });
          }
        } catch (chunkError) {
          // Log error but continue with next chunk instead of stopping
          console.error(`‚ùå Error fetching chunk ${i + 1}/${chunks.length} for ${companyInfo.company}:`, chunkError);
          
          // Get current saved progress to track failed chunks
          let currentSavedProgress = null;
          try {
            currentSavedProgress = await hybridCache.getDashboardState(progressKey);
          } catch (e) {
            // Ignore errors getting saved progress
          }
          
          // Save error state but don't mark as completely failed
          await hybridCache.setDashboardState(progressKey, {
            email,
            companyGuid: companyInfo.guid,
            tallylocId: companyInfo.tallyloc_id,
            status: 'in_progress',
            lastUpdated: Date.now(),
            chunksCompleted: i,
            totalChunks: chunks.length,
            error: `Chunk ${i + 1} failed: ${chunkError.message}`,
            failedChunks: [...(currentSavedProgress?.failedChunks || []), i]
          });
          
          // Continue with next chunk instead of throwing - allow download to complete
          // We'll retry failed chunks at the end if needed
          console.warn(`‚ö†Ô∏è Continuing with next chunk despite error in chunk ${i + 1}`);
          
          // Update progress to show we're continuing
          if (onProgress) {
            onProgress({
              current: i + 1,
              total: chunks.length,
              message: `Syncing ${companyInfo.company}: ${i + 1} / ${chunks.length} chunks (chunk ${i + 1} failed, continuing...)`,
              companyGuid: companyInfo.guid,
              companyName: companyInfo.company
            });
          }
          
          // Continue to next chunk instead of throwing
          continue;
        }
      }
      
      // After processing all chunks, retry any failed chunks
      let currentSavedProgress = null;
      try {
        currentSavedProgress = await hybridCache.getDashboardState(progressKey);
      } catch (e) {
        // Ignore errors
      }
      
      const failedChunks = currentSavedProgress?.failedChunks || [];
      if (failedChunks.length > 0) {
        console.log(`üîÑ Retrying ${failedChunks.length} failed chunks...`);
        
        for (const failedChunkIndex of failedChunks) {
          if (failedChunkIndex >= chunks.length) continue;
          
          const chunk = chunks[failedChunkIndex];
          const chunkPayload = {
            ...payload,
            fromdate: formatDateForAPI(chunk.start),
            todate: formatDateForAPI(chunk.end),
            serverslice: "No"
          };

          try {
            console.log(`üîÑ Retrying chunk ${failedChunkIndex + 1}/${chunks.length}...`);
            
            const chunkFetchResponse = await fetchWithTimeout(
              salesextractUrl,
              {
                method: 'POST',
                headers,
                body: JSON.stringify(chunkPayload),
              },
              300000, // 5 minutes timeout
              5 // 5 retries for failed chunks
            );

            const chunkResponseText = await chunkFetchResponse.text();
            if (chunkResponseText) {
              const chunkResponse = JSON.parse(chunkResponseText);
              if (chunkResponse && chunkResponse.vouchers && Array.isArray(chunkResponse.vouchers)) {
                allVouchers.push(...chunkResponse.vouchers);
                console.log(`‚úÖ Successfully retried chunk ${failedChunkIndex + 1}`);
              }
            }
            
            // Update progress to remove from failed chunks
            if (onProgress) {
              onProgress({
                current: chunks.length,
                total: chunks.length,
                message: `Syncing ${companyInfo.company}: Retrying failed chunks... (${failedChunks.length - (failedChunks.indexOf(failedChunkIndex) + 1)} remaining)`,
                companyGuid: companyInfo.guid,
                companyName: companyInfo.company
              });
            }
          } catch (retryError) {
            console.error(`‚ùå Retry failed for chunk ${failedChunkIndex + 1}:`, retryError);
            // Continue with next failed chunk even if retry fails
          }
        }
      }
      
      // If this is an update, ALWAYS merge with existing cache data to preserve old data
      if (isUpdate) {
        // Use pre-loaded existing vouchers, or try to load them again if pre-load failed
        let existingVouchers = existingVouchersForMerge;
        if (existingVouchers.length === 0) {
          try {
            const existingData = await hybridCache.getCompleteSalesData(companyInfo, email);
            if (existingData && existingData.data && existingData.data.vouchers && existingData.data.vouchers.length > 0) {
              existingVouchers = existingData.data.vouchers;
              console.log(`üìä Loaded ${existingVouchers.length} existing vouchers for merge (fallback)`);
            }
          } catch (error) {
            console.warn('‚ö†Ô∏è Could not load existing cache for merge:', error);
          }
        }
        
        if (existingVouchers.length > 0) {
          // Always preserve existing vouchers - this is critical to prevent data loss
          // If we have new vouchers, merge them; otherwise just keep ALL existing
          if (allVouchers.length > 0) {
            const existingIds = new Set(existingVouchers.map(v => {
              const mstid = v.mstid || v.MSTID || v.masterid || v.MASTERID;
              const alterid = v.alterid || v.ALTERID;
              const vchno = v.voucher_number || v.VCHNO || v.vchno || v.VCHNO;
              const date = v.cp_date || v.DATE || v.date || v.CP_DATE;
              if (mstid && alterid) return `${mstid}_${alterid}`;
              if (vchno && date) return `${vchno}_${date}`;
              if (mstid) return mstid.toString();
              return JSON.stringify({ vchno, date, amount: v.amount || v.AMT || v.amt });
            }));

            const newVouchers = allVouchers.filter(v => {
              const mstid = v.mstid || v.MSTID || v.masterid || v.MASTERID;
              const alterid = v.alterid || v.ALTERID;
              const vchno = v.voucher_number || v.VCHNO || v.vchno || v.VCHNO;
              const date = v.cp_date || v.DATE || v.date || v.CP_DATE;
              let id;
              if (mstid && alterid) id = `${mstid}_${alterid}`;
              else if (vchno && date) id = `${vchno}_${date}`;
              else if (mstid) id = mstid.toString();
              else id = JSON.stringify({ vchno, date, amount: v.amount || v.AMT || v.amt });
              return !existingIds.has(id);
            });
            
            console.log(`üìä Merging ${newVouchers.length} new vouchers with ${existingVouchers.length} existing vouchers (total: ${existingVouchers.length + newVouchers.length})`);
            allVouchers = [...existingVouchers, ...newVouchers];
          } else {
            // No new vouchers, but preserve ALL existing data
            console.log(`üìä No new vouchers found, preserving ALL ${existingVouchers.length} existing vouchers`);
            allVouchers = existingVouchers;
          }
          mergedData = { vouchers: allVouchers };
        } else {
          // No existing data found - this shouldn't happen in normal update flow
          // But if it does, use new vouchers (better than losing them)
          console.warn('‚ö†Ô∏è Update mode but no existing data found, using new vouchers only');
          mergedData = { vouchers: allVouchers };
        }
      } else {
        // Not an update, use new vouchers as-is
        mergedData = { vouchers: allVouchers };
      }
    } else {
      if (response && response.vouchers && Array.isArray(response.vouchers)) {
        allVouchers = response.vouchers;
        
        // If this is an update, ALWAYS merge with existing cache data to preserve old data
        if (isUpdate) {
          // Use pre-loaded existing vouchers, or try to load them again if pre-load failed
          let existingVouchers = existingVouchersForMerge;
          if (existingVouchers.length === 0) {
            try {
              const existingData = await hybridCache.getCompleteSalesData(companyInfo, email);
              if (existingData && existingData.data && existingData.data.vouchers && existingData.data.vouchers.length > 0) {
                existingVouchers = existingData.data.vouchers;
                console.log(`üìä Loaded ${existingVouchers.length} existing vouchers for merge (fallback, non-chunked)`);
              }
            } catch (error) {
              console.warn('‚ö†Ô∏è Could not load existing cache for merge (non-chunked):', error);
            }
          }
          
          if (existingVouchers.length > 0) {
            // Always preserve existing vouchers
            // If we have new vouchers, merge them; otherwise just keep ALL existing
            if (allVouchers.length > 0) {
              const existingIds = new Set(existingVouchers.map(v => {
                const mstid = v.mstid || v.MSTID || v.masterid || v.MASTERID;
                const alterid = v.alterid || v.ALTERID;
                const vchno = v.voucher_number || v.VCHNO || v.vchno || v.VCHNO;
                const date = v.cp_date || v.DATE || v.date || v.CP_DATE;
                if (mstid && alterid) return `${mstid}_${alterid}`;
                if (vchno && date) return `${vchno}_${date}`;
                if (mstid) return mstid.toString();
                return JSON.stringify({ vchno, date, amount: v.amount || v.AMT || v.amt });
              }));

              const newVouchers = allVouchers.filter(v => {
                const mstid = v.mstid || v.MSTID || v.masterid || v.MASTERID;
                const alterid = v.alterid || v.ALTERID;
                const vchno = v.voucher_number || v.VCHNO || v.vchno || v.VCHNO;
                const date = v.cp_date || v.DATE || v.date || v.CP_DATE;
                let id;
                if (mstid && alterid) id = `${mstid}_${alterid}`;
                else if (vchno && date) id = `${vchno}_${date}`;
                else if (mstid) id = mstid.toString();
                else id = JSON.stringify({ vchno, date, amount: v.amount || v.AMT || v.amt });
                return !existingIds.has(id);
              });
              
              console.log(`üìä Merging ${newVouchers.length} new vouchers with ${existingVouchers.length} existing vouchers (total: ${existingVouchers.length + newVouchers.length})`);
              allVouchers = [...existingVouchers, ...newVouchers];
            } else {
              // No new vouchers, but preserve ALL existing data
              console.log(`üìä No new vouchers found, preserving ALL ${existingVouchers.length} existing vouchers`);
              allVouchers = existingVouchers;
            }
            mergedData = { vouchers: allVouchers };
          } else {
            // No existing data found - this shouldn't happen in normal update flow
            console.warn('‚ö†Ô∏è Update mode but no existing data found (non-chunked), using new vouchers only');
            mergedData = { vouchers: allVouchers };
          }
        } else {
          // Not an update, use new vouchers as-is
          mergedData = { vouchers: allVouchers };
        }
      } else {
        // No response vouchers
        if (isUpdate) {
          // For updates, preserve existing data even if API returns nothing
          try {
            const existingData = await hybridCache.getCompleteSalesData(companyInfo, email);
            if (existingData && existingData.data && existingData.data.vouchers && existingData.data.vouchers.length > 0) {
              console.log(`üìä No new data from API, preserving ${existingData.data.vouchers.length} existing vouchers`);
              mergedData = existingData.data;
            } else {
              mergedData = { vouchers: [] };
            }
          } catch (error) {
            console.error('Error loading existing cache:', error);
            mergedData = { vouchers: [] };
          }
        } else {
          mergedData = { vouchers: [] };
        }
      }
    }

    // Final validation - but don't fail if we have some data (even if some chunks failed)
    if (isUpdate && (!mergedData.vouchers || !Array.isArray(mergedData.vouchers) || mergedData.vouchers.length === 0)) {
        try {
            const existingData = await hybridCache.getCompleteSalesData(companyInfo, email);
        if (existingData && existingData.data && existingData.data.vouchers && existingData.data.vouchers.length > 0) {
          mergedData = existingData.data;
          console.log('‚ö†Ô∏è No new data from update, preserving existing cache data');
        } else {
          // Don't throw error if we have no data - just log and continue
          console.warn('‚ö†Ô∏è Update resulted in empty data and no existing cache, but continuing...');
          mergedData = { vouchers: [] };
        }
      } catch (error) {
        // Don't throw - just log and continue with empty array
        console.warn('‚ö†Ô∏è Could not load existing cache:', error);
        mergedData = { vouchers: [] };
      }
    }

    if (!mergedData || !mergedData.vouchers || !Array.isArray(mergedData.vouchers)) {
      // Initialize empty array instead of throwing - better to have empty cache than crash
      console.warn('‚ö†Ô∏è Invalid data structure, initializing empty vouchers array');
      mergedData = { vouchers: [] };
    }

    const maxAlterId = calculateMaxAlterId(mergedData);
    const metadata = {
      booksfrom: booksfrom || formatDateForAPI(todayStr),
      lastaltid: maxAlterId
    };

    await hybridCache.setCompleteSalesData(companyInfo, mergedData, { ...metadata, email });
    
    // Mark progress as completed
    await hybridCache.setDashboardState(progressKey, {
      email,
      companyGuid: companyInfo.guid,
      tallylocId: companyInfo.tallyloc_id,
      status: 'completed',
      lastSyncedAlterId: maxAlterId,
      lastSyncedDate: todayStr,
      lastUpdated: Date.now(),
      chunksCompleted: chunks ? chunks.length : 0,
      totalChunks: chunks ? chunks.length : 0
    });

    console.log(`‚úÖ Successfully stored ${mergedData.vouchers.length} vouchers in cache`);
    return { success: true, count: mergedData.vouchers.length, lastAlterId: maxAlterId };

  } catch (error) {
    // Save error state
    try {
      await hybridCache.setDashboardState(progressKey, {
        email,
        companyGuid: companyInfo.guid,
        tallylocId: companyInfo.tallyloc_id,
        status: 'failed',
        lastUpdated: Date.now(),
        error: error.message
      });
    } catch (e) {
      console.error('Failed to save error state:', e);
    }
    console.error('Error syncing sales data:', error);
    throw error;
  }
};

/**
 * Unified Cache Sync Manager
 * Singleton pattern to manage cache sync operations globally.
 * Handles auto-sync on login, progress tracking, resume capability, and company switching.
 */
class CacheSyncManager {
  constructor() {
    this.isSyncing = false;
    this.progress = { current: 0, total: 0, message: '' };
    this.companyInfo = null;
    this.syncPromise = null;
    this.subscribers = new Set();
    this.syncStartTime = null;
    this.autoSyncQueue = [];
    this.autoSyncInProgress = false;
    this.initialized = false;
  }

  /**
   * Initialize the sync manager - check for incomplete syncs and resume
   */
  async init() {
    if (this.initialized) return;
    
    const email = getUserEmail();
    if (!email) {
      console.log('No user email found, skipping sync initialization');
      this.initialized = true;
      return;
    }

    try {
      // Check for incomplete syncs and resume them
      await this.resumeIncompleteSyncs(email);
    } catch (error) {
      console.error('Error initializing sync manager:', error);
    }
    
    this.initialized = true;
    
    // Listen for connections updates to trigger auto-sync
    const connectionsHandler = () => {
      this.handleConnectionsUpdate();
    };
    window.addEventListener('connectionsUpdated', connectionsHandler);

    // Listen for storage events (cross-tab sync)
    const storageHandler = (e) => {
      if (e.key === 'allConnections') {
        this.handleConnectionsUpdate();
      }
    };
    window.addEventListener('storage', storageHandler);
    
    // Also trigger immediately if connections are already available
    try {
      const connectionsStr = sessionStorage.getItem('allConnections');
      if (connectionsStr) {
        // Small delay to ensure everything is initialized
        setTimeout(() => {
          this.handleConnectionsUpdate();
        }, 1000);
      }
    } catch (e) {
      // Ignore
    }
  }

  /**
   * Resume incomplete syncs on app start
   */
  async resumeIncompleteSyncs(email) {
    try {
      // Get all companies from sessionStorage
      const connectionsStr = sessionStorage.getItem('allConnections');
      if (!connectionsStr) return;

      const connections = JSON.parse(connectionsStr);
      const eligibleCompanies = connections.filter(c => 
        c.status === 'Connected' && 
        (c.access_type === 'Internal' || c.access_type === 'Full Access')
      );

      for (const company of eligibleCompanies) {
        const progressKey = getSyncProgressKey(email, company.guid);
        try {
          const progress = await hybridCache.getDashboardState(progressKey);
          if (progress && progress.status === 'in_progress') {
            console.log(`üìã Found incomplete sync for ${company.company}, resuming...`);
            // Add to auto-sync queue
            this.queueCompanyForSync(company);
          }
        } catch (e) {
          // No progress found or error reading
        }
      }

      // Start processing queue if there are incomplete syncs
      if (this.autoSyncQueue.length > 0) {
        this.processAutoSyncQueue();
      }
    } catch (error) {
      console.error('Error resuming incomplete syncs:', error);
    }
  }

  /**
   * Handle connections update - trigger auto-sync for new companies
   */
  async handleConnectionsUpdate() {
    const email = getUserEmail();
    if (!email) return;

    try {
      const connectionsStr = sessionStorage.getItem('allConnections');
      if (!connectionsStr) return;

      const connections = JSON.parse(connectionsStr);
      const eligibleCompanies = connections.filter(c => 
        c.status === 'Connected' && 
        (c.access_type === 'Internal' || c.access_type === 'Full Access')
      );

      // Check each company - sync if not already completed or in progress
      for (const company of eligibleCompanies) {
        // Skip if already in queue
        if (this.autoSyncQueue.find(c => c.guid === company.guid)) {
          continue;
        }
        
        // Skip if currently being synced
        if (this.isSyncing && this.companyInfo && this.companyInfo.guid === company.guid) {
          continue;
        }
        
        const progressKey = getSyncProgressKey(email, company.guid);
        try {
          const progress = await hybridCache.getDashboardState(progressKey);
          // Only queue if not completed and not already in progress
          if (!progress || (progress.status !== 'completed' && progress.status !== 'in_progress')) {
            this.queueCompanyForSync(company);
          }
        } catch (e) {
          // No progress found, queue for sync
          this.queueCompanyForSync(company);
        }
      }

      // Start processing queue if not already processing
      if (this.autoSyncQueue.length > 0 && !this.autoSyncInProgress) {
        this.processAutoSyncQueue();
      }
    } catch (error) {
      console.error('Error handling connections update:', error);
    }
  }

  /**
   * Start auto-sync for multiple companies (called after login)
   */
  async startAutoSyncForCompanies(companies) {
    if (!companies || companies.length === 0) return;

    const email = getUserEmail();
    if (!email) {
      console.warn('Cannot start auto-sync: no user email found');
      return;
    }

    // Filter for eligible companies
    const eligibleCompanies = companies.filter(c => 
      c.status === 'Connected' && 
      (c.access_type === 'Internal' || c.access_type === 'Full Access')
    );

    console.log(`üöÄ Starting auto-sync for ${eligibleCompanies.length} companies`);

    // Check each company - only queue if not already completed
    for (const company of eligibleCompanies) {
      const progressKey = getSyncProgressKey(email, company.guid);
      try {
        const progress = await hybridCache.getDashboardState(progressKey);
        // Only queue if not completed
        if (!progress || progress.status !== 'completed') {
          this.queueCompanyForSync(company);
        }
      } catch (e) {
        // No progress found, queue for sync
        this.queueCompanyForSync(company);
      }
    }

    // Start processing queue
    this.processAutoSyncQueue();
  }

  /**
   * Queue a company for auto-sync
   */
  queueCompanyForSync(company) {
    // Check if already in queue
    if (this.autoSyncQueue.find(c => c.guid === company.guid)) {
      return;
    }
    this.autoSyncQueue.push(company);
  }

  /**
   * Process auto-sync queue sequentially
   */
  async processAutoSyncQueue() {
    if (this.autoSyncInProgress || this.autoSyncQueue.length === 0) {
      return;
    }

    this.autoSyncInProgress = true;
    const email = getUserEmail();

    while (this.autoSyncQueue.length > 0) {
      const company = this.autoSyncQueue.shift();
      
      try {
        console.log(`üîÑ Auto-syncing company: ${company.company}`);
        await this.startSync(company, async (companyInfo, progressCallback) => {
          return await syncSalesDataInternal(companyInfo, email, progressCallback);
        });
      } catch (error) {
        console.error(`‚ùå Auto-sync failed for ${company.company}:`, error);
        // Continue with next company
      }
    }

    this.autoSyncInProgress = false;
  }

  /**
   * Subscribe to progress updates
   */
  subscribe(callback) {
    this.subscribers.add(callback);
    if (this.isSyncing) {
      callback(this.progress);
    }
    return () => {
      this.subscribers.delete(callback);
    };
  }

  /**
   * Notify all subscribers of progress update
   */
  notifySubscribers(progress) {
    this.progress = progress;
    this.subscribers.forEach(callback => {
      try {
        callback(progress);
      } catch (error) {
        console.error('Error in sync progress subscriber:', error);
      }
    });
  }

  /**
   * Check if a sync is currently in progress
   */
  isSyncInProgress() {
    return this.isSyncing;
  }

  /**
   * Get current progress
   */
  getProgress() {
    return { ...this.progress };
  }

  /**
   * Get progress for a specific company
   */
  async getCompanyProgress(companyInfo) {
    const email = getUserEmail();
    if (!email || !companyInfo) {
      return null;
    }

    // First check if this company is currently being synced
    if (this.isSyncing && this.companyInfo && this.companyInfo.guid === companyInfo.guid) {
      return {
        ...this.progress,
        companyGuid: companyInfo.guid,
        companyName: companyInfo.company
      };
    }

    // Otherwise check stored progress
    const progressKey = getSyncProgressKey(email, companyInfo.guid);
    try {
      const progress = await hybridCache.getDashboardState(progressKey);
      if (progress && progress.status === 'in_progress') {
        // Convert stored progress to display format
        const current = progress.chunksCompleted || 0;
        const total = progress.totalChunks || 0;
        return {
          current,
          total,
          message: total > 0 
            ? `Syncing ${companyInfo.company}: ${current} / ${total} chunks`
            : `Syncing ${companyInfo.company}...`,
          companyGuid: companyInfo.guid,
          companyName: companyInfo.company
        };
      }
      return null;
    } catch (error) {
      console.error('Error getting company progress:', error);
      return null;
    }
  }

  /**
   * Get current company info being synced
   */
  getCompanyInfo() {
    return this.companyInfo;
  }

  /**
   * Check if sync is for the same company
   */
  isSameCompany(companyInfo) {
    if (!this.companyInfo || !companyInfo) return false;
    return (
      this.companyInfo.tallyloc_id === companyInfo.tallyloc_id &&
      this.companyInfo.guid === companyInfo.guid
    );
  }

  /**
   * Start a sync operation
   */
  async startSync(companyInfo, syncFunction) {
    // If sync is already in progress for the same company, return existing promise
    if (this.isSyncing && this.isSameCompany(companyInfo)) {
      return this.syncPromise;
    }

    // If sync is in progress for a different company, wait for it to complete
    if (this.isSyncing && !this.isSameCompany(companyInfo)) {
      try {
        await this.syncPromise;
      } catch (error) {
        // Ignore errors from previous sync
      }
    }

    // Start new sync
    this.isSyncing = true;
    this.companyInfo = companyInfo;
    this.syncStartTime = Date.now();
    this.notifySubscribers({ current: 0, total: 0, message: 'Starting sync...' });

    const progressCallback = (progress) => {
      this.notifySubscribers(progress);
    };

    this.syncPromise = syncFunction(companyInfo, progressCallback)
      .then((result) => {
        console.log('‚úÖ Sync completed successfully');
        return result;
      })
      .catch((error) => {
        console.error('‚ùå Sync failed:', error);
        throw error;
      })
      .finally(() => {
        this.isSyncing = false;
        this.companyInfo = null;
        this.syncPromise = null;
        this.syncStartTime = null;
        setTimeout(() => {
          if (!this.isSyncing) {
            this.notifySubscribers({ current: 0, total: 0, message: '' });
          }
        }, 1000);
      });

    return this.syncPromise;
  }

  /**
   * Cancel current sync
   */
  cancelSync() {
    if (this.isSyncing) {
      console.log('üõë Cancelling sync...');
      this.isSyncing = false;
      this.companyInfo = null;
      this.syncPromise = null;
      this.syncStartTime = null;
      this.notifySubscribers({ current: 0, total: 0, message: 'Cancelled' });
    }
  }
}

// Export singleton instance
export const cacheSyncManager = new CacheSyncManager();

// Export sync functions for backward compatibility
export const syncSalesData = async (companyInfo, onProgress = () => {}) => {
  if (!companyInfo) {
    throw new Error('No company selected');
  }

  const email = getUserEmail();
  if (!email) {
    throw new Error('No user email found');
  }

  // Subscribe to progress updates
  const unsubscribe = cacheSyncManager.subscribe(onProgress);

  try {
    const result = await cacheSyncManager.startSync(companyInfo, async (companyInfo, progressCallback) => {
      return await syncSalesDataInternal(companyInfo, email, progressCallback);
    });
    return result;
  } finally {
    unsubscribe();
  }
};

export const syncCustomers = async (companyInfo) => {
  if (!companyInfo) throw new Error('No company selected');

  const { tallyloc_id, company, guid } = companyInfo;
  const cacheKey = `ledgerlist-w-addrs_${tallyloc_id}_${company}`;

  try {
    const data = await apiPost(`/api/tally/ledgerlist-w-addrs?ts=${Date.now()}`, {
      tallyloc_id,
      company,
      guid
    });

    if (data && data.ledgers && Array.isArray(data.ledgers)) {
      sessionStorage.setItem(cacheKey, JSON.stringify(data.ledgers));
      return { success: true, count: data.ledgers.length };
    }
    throw new Error(data?.error || 'Failed to fetch customers');
  } catch (error) {
    console.error('Error syncing customers:', error);
    throw error;
  }
};

export const syncItems = async (companyInfo) => {
  if (!companyInfo) throw new Error('No company selected');

  const { tallyloc_id, company, guid } = companyInfo;
  const cacheKey = `stockitems_${tallyloc_id}_${company}`;

  try {
    const data = await apiPost(`/api/tally/stockitem?ts=${Date.now()}`, {
      tallyloc_id,
      company,
      guid
    });

    if (data && data.stockItems && Array.isArray(data.stockItems)) {
      const decryptedItems = deobfuscateStockItems(data.stockItems);
      sessionStorage.setItem(cacheKey, JSON.stringify(decryptedItems));
      return { success: true, count: decryptedItems.length };
    }
    throw new Error(data?.error || 'Failed to fetch stock items');
  } catch (error) {
    console.error('Error syncing items:', error);
    throw error;
  }
};

// Get customers from cache (sessionStorage)
export const getCustomersFromOPFS = async (cacheKey) => {
  try {
    const cached = sessionStorage.getItem(cacheKey);
    if (cached) {
      const customers = JSON.parse(cached);
      if (Array.isArray(customers) && customers.length > 0) {
        console.log(`‚úÖ Retrieved ${customers.length} customers from cache (${cacheKey})`);
        return customers;
      }
    }
    console.log(`‚ö†Ô∏è No customers found in cache for key: ${cacheKey}`);
    return null;
  } catch (error) {
    console.error('Error reading customers from cache:', error);
    return null;
  }
};

// Get items from cache (sessionStorage)
export const getItemsFromOPFS = async (cacheKey) => {
  try {
    const cached = sessionStorage.getItem(cacheKey);
    if (cached) {
      const items = JSON.parse(cached);
      if (Array.isArray(items) && items.length > 0) {
        console.log(`‚úÖ Retrieved ${items.length} items from cache (${cacheKey})`);
        return items;
      }
    }
    console.log(`‚ö†Ô∏è No items found in cache for key: ${cacheKey}`);
    return null;
  } catch (error) {
    console.error('Error reading items from cache:', error);
    return null;
  }
};

